{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Deep learning NER con bilstm y crf - clinicalEmb-300-skyp\n",
    "## NewDataset Lung Cancer\n",
    "\n",
    "### Definicion de Parametro e Hiperparametros del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./libs')\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from itertools import islice\n",
    "\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report as eskclarep\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from seqeval.metrics import classification_report as seqclarep\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Concatenate, Lambda, Input, LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, InputLayer, Activation, Flatten, Masking\n",
    "from tensorflow.keras.optimizers import Adam, schedules\n",
    "\n",
    "from tf2crf import CRF as crf6\n",
    "from mwrapper import ModelWithCRFLoss, ModelWithCRFLossDSCLoss\n",
    "from utils import build_matrix_embeddings as bme, plot_model_performance, logits_to_tokens, report_to_df2\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import datetime, os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # TF 2.1+\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "MODEL         = 'new-clinical-base_model_epoch_60'\n",
    "logs_base_dir = \"./logs\"\n",
    "log_dir       = logs_base_dir + \"/\" + MODEL\n",
    "save_base_dir = './model-save'\n",
    "save_dir      = save_base_dir + \"/\" + MODEL\n",
    "\n",
    "os.makedirs(logs_base_dir, exist_ok=True)\n",
    "os.makedirs(log_dir,       exist_ok=True)\n",
    "os.makedirs(save_base_dir, exist_ok=True)\n",
    "os.makedirs(save_dir,      exist_ok=True)\n",
    "\n",
    "#%load_ext tensorboard\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            \n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****** DEFINICION DE PARAMETROS *********\n",
    "NUM_WORDS       = 13705 + 2\n",
    "LEN_SENTS       = 306\n",
    "NUM_TAGS        = 37 + 2\n",
    "\n",
    "\n",
    "# ****** DEFINICION DE HIPERPARAMETROS *********\n",
    "_EPOCHS         = 50\n",
    "EMBED_DIM       = 300\n",
    "_DROPOUT        = 0.5\n",
    "_BACH_SIZE      = 512 + (256+128)\n",
    "_LEARN_RATE     = 5e-3\n",
    "NUM_FOLDS       = 7\n",
    "VAL_SPLIT       = 0.2\n",
    "\n",
    "prime_data_fold = []\n",
    "total_data_fold = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se cargan los datos de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sentences = []\n",
    "\n",
    "with open(\"./vectors/sentences_train.txt\", \"rb\") as fp:\n",
    "    total_sentences = pickle.load(fp)\n",
    "    \n",
    "    \n",
    "## ********** Oraciones ********** ##\n",
    "word2idx = np.load('./vectors/word2index.npy', allow_pickle=True).item()\n",
    "idx2word = {v: k for k, v in word2idx.items()}\n",
    "\n",
    "idx2tag  = np.load('./vectors/index2tag.npy', allow_pickle=True).item()\n",
    "\n",
    "x_inputs = np.load('./vectors/X_train.npy')\n",
    "\n",
    "print(x_inputs.shape)\n",
    "\n",
    "## ********** Salidas ********** ##\n",
    "y_output = np.load('./vectors/y_train.npy')\n",
    "\n",
    "\n",
    "print(y_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(type(y_train))\n",
    "#print(y_train[0])\n",
    "#(11773, 310)\n",
    "#(2790, 310)\n",
    "#(3480, 310)\n",
    "print(total_sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas de carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('**** Diccionario de palabras: ****\\n')\n",
    "#for key, value in feature_lemma_to_idx.items():\n",
    "#    if value == 10:\n",
    "#        break\n",
    "#    else:\n",
    "#        print(key, ' : ', value)\n",
    "        \n",
    "#print(X_train[0], \"\\n\")\n",
    "#print(len(X_train))\n",
    "\n",
    "#print(y_train[0])\n",
    "#print(len(y_train))\n",
    "#print(len(y_test))\n",
    "#print(len(y_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se carga el embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../oswaldo-nubes/embedding/Biomed/clinical/cased/skipgram/d300/clinic_es.vec'\n",
    "embedding_matrix = bme(file, NUM_WORDS, EMBED_DIM, word2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definici√≥n del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(print_sumary=0):\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "    with strategy.scope():\n",
    "        loss      = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        optimizer = keras.optimizers.Adam(lr=_LEARN_RATE)\n",
    "        \n",
    "        # Input Layer\n",
    "        input1 = Input(shape=(LEN_SENTS,), dtype='int32')\n",
    "\n",
    "        # Embedding Layer\n",
    "        sentences = Embedding(NUM_WORDS,\n",
    "                              EMBED_DIM,\n",
    "                              input_length=LEN_SENTS,\n",
    "                              weights=[embedding_matrix],\n",
    "                              trainable=False,\n",
    "                              mask_zero=False)(input1)\n",
    "\n",
    "        drp_sentences = Dropout(_DROPOUT, name='dropout_sentences')(sentences)\n",
    "\n",
    "        # BI-LSTM Layer\n",
    "        myModel = Bidirectional(LSTM(EMBED_DIM, \n",
    "                                     return_sequences=True\n",
    "                                    ),\n",
    "                                name='bilstm1')(drp_sentences)\n",
    "\n",
    "\n",
    "        myModel  = Dropout(_DROPOUT, name='dropout_lstm')(myModel)\n",
    "        myModel  = Dense(units=EMBED_DIM * 2, activation='relu')(myModel)\n",
    "        myModel  = Dense(units=NUM_TAGS, activation='relu')(myModel)\n",
    "\n",
    "        myModel  = Masking(mask_value=0.,input_shape=(LEN_SENTS, NUM_TAGS))(myModel)\n",
    "\n",
    "        crf = crf6(units=NUM_TAGS, name=\"ner_crf\")\n",
    "        predictions = crf(myModel)\n",
    "\n",
    "        base_model = Model(inputs=input1, outputs=predictions)\n",
    "        model = ModelWithCRFLoss(base_model, sparse_target=True)\n",
    "\n",
    "        #model.compile(optimizer='adam')\n",
    "        model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "    if print_sumary == 1:\n",
    "        base_model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entranamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=NUM_FOLDS, shuffle=True)\n",
    "\n",
    "fold_no = 1\n",
    "for train_index, test_index in kfold.split(x_inputs):\n",
    "    \n",
    "    model = get_model(fold_no)\n",
    "    \n",
    "    # Fit the best model\n",
    "    history = model.fit([x_inputs[train_index]], y_output[train_index],\n",
    "                        validation_split = VAL_SPLIT,\n",
    "                        batch_size       = _BACH_SIZE,\n",
    "                        epochs           = _EPOCHS,\n",
    "                        verbose          = 2)\n",
    "    \n",
    "    ### se almacena el modelo\n",
    "    \n",
    "    \n",
    "    ### Evaluamos el modelo y calculamos el valor de precision con respecto a los datos de prueba\n",
    "    scores = model.evaluate([x_inputs[test_index]], y_output[test_index])\n",
    "    print(f\"{model.metrics_names[1]}: {scores[1] * 100}\")\n",
    "    \n",
    "    \n",
    "    ###  Procedemos a Graficar el comportamiento del Entrenamiento, tanto del conjunto  \n",
    "    ### de entrenamiento  como el de validaci√≥n con respecto a la cantidad de epocas\n",
    "    plot_model_performance(\n",
    "        train_loss     = history.history.get('loss', []),\n",
    "        train_acc      = history.history.get('accuracy', []),\n",
    "        train_val_loss = history.history.get('val_loss_val', []),\n",
    "        train_val_acc  = history.history.get('val_val_accuracy', [])\n",
    "    )\n",
    "    \n",
    "    ### Hacemos la prediccion sobre el conjunto de pruebas\n",
    "    \n",
    "    #print(idx2tag[6])\n",
    "    prediction = model.predict([x_inputs[test_index]])\n",
    "    \n",
    "    y_pred = logits_to_tokens(prediction, idx2tag)\n",
    "    #print(y_pred[0])\n",
    "    \n",
    "    ### Hallamos los valores de F1 score, recall, precision\n",
    "\n",
    "    y_true = []\n",
    "    for i, index in enumerate(test_index):\n",
    "        oracion = total_sentences[index]\n",
    "        row_sent = []\n",
    "\n",
    "        for j, lista_palabras in enumerate(oracion):\n",
    "            row_sent.append(lista_palabras[1])\n",
    "\n",
    "        qekk = ['-PAD-'] * LEN_SENTS\n",
    "\n",
    "        qekk[:len(row_sent)] = row_sent\n",
    "        y_true.append(qekk)\n",
    "    \n",
    "  \n",
    "    \n",
    "    li1 = sum(y_true, [])\n",
    "    li2 = sum(y_pred, [])\n",
    "\n",
    "    results = pd.DataFrame(columns=['Expected', 'Predicted'])\n",
    "\n",
    "    results['Expected'] = li1\n",
    "    results['Predicted'] = li2\n",
    "    \n",
    "    #print('\\nclassification_report:\\n', seqclarep(y_true, y_pred))\n",
    "\n",
    "    print(\"precision: {:.1%}\".format(precision_score(y_true, y_pred)))\n",
    "    print(\"   recall: {:.1%}\".format(recall_score(y_true,    y_pred)))\n",
    "    print(\" accuracy: {:.1%}\".format(accuracy_score(y_true,  y_pred)))\n",
    "    print(\" F1-score: {:.1%}\".format(f1_score(y_true,        y_pred)))\n",
    "    \n",
    "    info = []\n",
    "\n",
    "    info.append(\"precision: {:.1%}\".format(precision_score(y_true, y_pred)))\n",
    "    info.append(\"   recall: {:.1%}\".format(recall_score(y_true,    y_pred)))\n",
    "    info.append(\" accuracy: {:.1%}\".format(accuracy_score(y_true,  y_pred)))\n",
    "    info.append(\" F1-score: {:.1%}\".format(f1_score(y_true,        y_pred)))\n",
    "\n",
    "    prime_data_fold.append(info)\n",
    "    \n",
    "    ### Hallamos el calculo de cada una de las etiquetas por separado\n",
    "    report = eskclarep(results['Expected'], results['Predicted'])\n",
    "    #print('\\nclassification_report:\\n', report)\n",
    "\n",
    "    data = {'y_Actual':    results['Expected'],\n",
    "            'y_Predicted': results['Predicted']\n",
    "            }\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'], margins = True)\n",
    "\n",
    "    sn.heatmap(confusion_matrix, annot=True)\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    plt.show()\n",
    "    \n",
    "    rep_kfl = report_to_df2(report, '-fol' + str(fold_no))\n",
    "    \n",
    "    total_data_fold.append(rep_kfl)\n",
    "    \n",
    "    print(rep_kfl)\n",
    "    \n",
    "    ######### ----- Codigo nuevo para salvar los array: y_true, y_pred ----------\n",
    "    array_result = []\n",
    "    array_result.append((y_true, y_pred))# Se usara para calcular NER Eval\n",
    "    arrayNER = np.array(array_result)\n",
    "    \n",
    "    dirName= './NER-scoring-data/'\n",
    "    fileName =  dirName + \"fold-\" + str(fold_no) + '.npy'\n",
    "    np.save(fileName, arrayNER)\n",
    "    \n",
    "    #####---------------------------------------------------------------------\n",
    "        \n",
    "        \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### se almacena el resultado del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = open('prime_data_' + MODEL + '.pkl', 'wb')\n",
    "pickle.dump(prime_data_fold, output1)\n",
    "output1.close()\n",
    "\n",
    "output2 = open('total_data_' + MODEL + '.pkl', 'wb')\n",
    "pickle.dump(total_data_fold, output2)\n",
    "output2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # Ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NER_samples = [\n",
    "    \"Paciente diagnosticado con c√°ncer de pulm√≥n en marzo de 2019. \".split(),\n",
    "    \"No cl√≠nica urinaria ni respiratoria aguda .\".split(),\n",
    "    \"Niega HTA, DM y DM .\".split(),\n",
    "    \"No se observan signos de insuficiencia card√≠aca .\".split(),\n",
    "    \"Paciente tratado con 3 ciclos de de carboplatino .\".split()\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "print(\"Examples: \\n\", NER_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertimos las Entradas del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NER_samples_X    = []\n",
    "\n",
    "for s1 in NER_samples:\n",
    "    s1_int = []\n",
    "    for w in s1:\n",
    "        try:\n",
    "            s1_int.append(word2idx[w.lower()])\n",
    "        except KeyError:\n",
    "            s1_int.append(word2idx['-OOV-'])\n",
    "    NER_samples_X.append(s1_int)\n",
    "\n",
    "NER_samples_X = pad_sequences(NER_samples_X, maxlen=LEN_SENTS, padding='post')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Examples: \\n\", NER_samples_X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se ejecuta la predici√≥n con la entrada de ejemplo en el modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = model.predict(NER_samples_X)\n",
    "print(\"NER: \\n\", predictions1, predictions1.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversi√≥n de la salida del modelo a un lista de indices de tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_tokens1 = logits_to_tokens(predictions1, idx2tag)\n",
    "\n",
    "\n",
    "print(\"NER: \\n\", log_tokens1[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultado de NER: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h, oracc in enumerate(NER_samples):\n",
    "    heads = oracc\n",
    "    body  = [log_tokens1[h][:len(oracc)]]\n",
    "    display(HTML(\"<div style='overflow-x: auto; white-space: nowrap;'>\" + \n",
    "                 tabulate(body, headers=heads, tablefmt=\"html\") + \n",
    "                 \"</div>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
